{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"This is the NLP session that is going on and finally we are happy. Is everyone happy. iNeuron is company where we teach all the tech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the NLP session that is going on and finally we are happy.',\n",
       " 'Is everyone happy.',\n",
       " 'iNeuron is company where we teach all the tech']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(paragraph) # Paragraph into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'the',\n",
       " 'NLP',\n",
       " 'session',\n",
       " 'that',\n",
       " 'is',\n",
       " 'going',\n",
       " 'on',\n",
       " 'and',\n",
       " 'finally',\n",
       " 'we',\n",
       " 'are',\n",
       " 'happy',\n",
       " '.',\n",
       " 'Is',\n",
       " 'everyone',\n",
       " 'happy',\n",
       " '.',\n",
       " 'iNeuron',\n",
       " 'is',\n",
       " 'company',\n",
       " 'where',\n",
       " 'we',\n",
       " 'teach',\n",
       " 'all',\n",
       " 'the',\n",
       " 'tech']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(paragraph) # Tokenization : Converts sentence to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"going\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'final'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is the NLP session that is going on and finally we are happy. Is everyone happy. iNeuron is company where we teach all the tech'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the NLP session that is going on and finally we are happy.',\n",
       " 'Is everyone happy.',\n",
       " 'iNeuron is company where we teach all the tech']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thi', 'is', 'the', 'nlp', 'session', 'that', 'is', 'go', 'on', 'and', 'final', 'we', 'are', 'happi', '.']\n",
      "['Is', 'everyon', 'happi', '.']\n",
      "['ineuron', 'is', 'compani', 'where', 'we', 'teach', 'all', 'the', 'tech']\n"
     ]
    }
   ],
   "source": [
    "# Applying Stemming\n",
    "corpus=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi is the nlp session that is go on and final we are happi .',\n",
       " 'Is everyon happi .',\n",
       " 'ineuron is compani where we teach all the tech']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'the', 'NLP', 'session', 'that', 'is', 'going', 'on', 'and', 'finally', 'we', 'are', 'happy', '.']\n",
      "['Is', 'everyone', 'happy', '.']\n",
      "['iNeuron', 'is', 'company', 'where', 'we', 'teach', 'all', 'the', 'tech']\n"
     ]
    }
   ],
   "source": [
    "# Appling Tokenization\n",
    "\n",
    "corpus=[]\n",
    "for i in range(len(sentence)):\n",
    "    words=nltk.word_tokenize(sentence[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the NLP session that is going on and finally we are happy .',\n",
       " 'Is everyone happy .',\n",
       " 'iNeuron is company where we teach all the tech']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"\n",
    "Ratan Naval Tata (Ratan Ṭāṭā, born 28 December 1937) is an Indian industrialist, philanthropist, and a former chairman of Tata Sons. He was the chairman of Tata Group, from 1990 to 2012, and again, as interim chairman, from October 2016 through February 2017, and continues to head its charitable trusts.[3][4] He is the recipient of two civilian awards of India, the Padma Vibhushan (2008), the second highest civilian honour, and the Padma Bhushan (2000), the third highest civilian honour.[5]\n",
    "\n",
    "Born in 1937, he is a heir of the Tata family, and son of Naval Tata who was later adopted by Ratanji Tata, son of Jamsetji Tata, the founder of Tata Group. He is an alumnus of the Cornell University College of Architecture and Harvard Business School through the Advanced Management Program that he completed in 1975.[6] He joined his company in 1961 when he used to work on the shop floor of Tata Steel, and was the apparent successor to J. R. D. Tata upon the latter's retirement in 1991. He got Tata Tea to acquire Tetley, Tata Motors to acquire Jaguar Land Rover, and Tata Steel to acquire Corus, in an attempt to turn Tata from a largely India-centrist group into a global business. Around 60-65% of his profits are donated to charity making him one of the most significant philanthropists in the world.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nRatan Naval Tata (Ratan Ṭāṭā, born 28 December 1937) is an Indian industrialist, philanthropist, and a former chairman of Tata Sons. He was the chairman of Tata Group, from 1990 to 2012, and again, as interim chairman, from October 2016 through February 2017, and continues to head its charitable trusts.[3][4] He is the recipient of two civilian awards of India, the Padma Vibhushan (2008), the second highest civilian honour, and the Padma Bhushan (2000), the third highest civilian honour.[5]\\n\\nBorn in 1937, he is a heir of the Tata family, and son of Naval Tata who was later adopted by Ratanji Tata, son of Jamsetji Tata, the founder of Tata Group. He is an alumnus of the Cornell University College of Architecture and Harvard Business School through the Advanced Management Program that he completed in 1975.[6] He joined his company in 1961 when he used to work on the shop floor of Tata Steel, and was the apparent successor to J. R. D. Tata upon the latter's retirement in 1991. He got Tata Tea to acquire Tetley, Tata Motors to acquire Jaguar Land Rover, and Tata Steel to acquire Corus, in an attempt to turn Tata from a largely India-centrist group into a global business. Around 60-65% of his profits are donated to charity making him one of the most significant philanthropists in the world.\\n\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    # print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata ( ratan ṭāṭā , born 28 decemb 1937 ) is an indian industrialist , philanthropist , and a former chairman of tata son .',\n",
       " 'He wa the chairman of tata group , from 1990 to 2012 , and again , as interim chairman , from octob 2016 through februari 2017 , and continu to head it charit trust .',\n",
       " '[ 3 ] [ 4 ] He is the recipi of two civilian award of india , the padma vibhushan ( 2008 ) , the second highest civilian honour , and the padma bhushan ( 2000 ) , the third highest civilian honour .',\n",
       " '[ 5 ] born in 1937 , he is a heir of the tata famili , and son of naval tata who wa later adopt by ratanji tata , son of jamsetji tata , the founder of tata group .',\n",
       " 'He is an alumnu of the cornel univers colleg of architectur and harvard busi school through the advanc manag program that he complet in 1975 .',\n",
       " \"[ 6 ] He join hi compani in 1961 when he use to work on the shop floor of tata steel , and wa the appar successor to J. R. D. tata upon the latter 's retir in 1991 .\",\n",
       " 'He got tata tea to acquir tetley , tata motor to acquir jaguar land rover , and tata steel to acquir coru , in an attempt to turn tata from a larg india-centrist group into a global busi .',\n",
       " 'around 60-65 % of hi profit are donat to chariti make him one of the most signific philanthropist in the world .']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    # print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ratan Naval Tata ( Ratan Ṭāṭā , born 28 December 1937 ) is an Indian industrialist , philanthropist , and a former chairman of Tata Sons .',\n",
       " 'He wa the chairman of Tata Group , from 1990 to 2012 , and again , a interim chairman , from October 2016 through February 2017 , and continues to head it charitable trust .',\n",
       " '[ 3 ] [ 4 ] He is the recipient of two civilian award of India , the Padma Vibhushan ( 2008 ) , the second highest civilian honour , and the Padma Bhushan ( 2000 ) , the third highest civilian honour .',\n",
       " '[ 5 ] Born in 1937 , he is a heir of the Tata family , and son of Naval Tata who wa later adopted by Ratanji Tata , son of Jamsetji Tata , the founder of Tata Group .',\n",
       " 'He is an alumnus of the Cornell University College of Architecture and Harvard Business School through the Advanced Management Program that he completed in 1975 .',\n",
       " \"[ 6 ] He joined his company in 1961 when he used to work on the shop floor of Tata Steel , and wa the apparent successor to J. R. D. Tata upon the latter 's retirement in 1991 .\",\n",
       " 'He got Tata Tea to acquire Tetley , Tata Motors to acquire Jaguar Land Rover , and Tata Steel to acquire Corus , in an attempt to turn Tata from a largely India-centrist group into a global business .',\n",
       " 'Around 60-65 % of his profit are donated to charity making him one of the most significant philanthropist in the world .']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW { Bag Of Words }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nRatan Naval Tata (Ratan Ṭāṭā, born 28 December 1937) is an Indian industrialist, philanthropist, and a former chairman of Tata Sons.',\n",
       " 'He was the chairman of Tata Group, from 1990 to 2012, and again, as interim chairman, from October 2016 through February 2017, and continues to head its charitable trusts.',\n",
       " '[3][4] He is the recipient of two civilian awards of India, the Padma Vibhushan (2008), the second highest civilian honour, and the Padma Bhushan (2000), the third highest civilian honour.',\n",
       " '[5]\\n\\nBorn in 1937, he is a heir of the Tata family, and son of Naval Tata who was later adopted by Ratanji Tata, son of Jamsetji Tata, the founder of Tata Group.',\n",
       " 'He is an alumnus of the Cornell University College of Architecture and Harvard Business School through the Advanced Management Program that he completed in 1975.',\n",
       " \"[6] He joined his company in 1961 when he used to work on the shop floor of Tata Steel, and was the apparent successor to J. R. D. Tata upon the latter's retirement in 1991.\",\n",
       " 'He got Tata Tea to acquire Tetley, Tata Motors to acquire Jaguar Land Rover, and Tata Steel to acquire Corus, in an attempt to turn Tata from a largely India-centrist group into a global business.',\n",
       " 'Around 60-65% of his profits are donated to charity making him one of the most significant philanthropists in the world.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ratan', 'naval', 'tata', 'ratan', 'born', '28', 'decemb', '1937', 'is', 'an', 'indian', 'industrialist', 'philanthropist', 'and', 'a', 'former', 'chairman', 'of', 'tata', 'son']\n",
      "['he', 'wa', 'the', 'chairman', 'of', 'tata', 'group', 'from', '1990', 'to', '2012', 'and', 'again', 'as', 'interim', 'chairman', 'from', 'octob', '2016', 'through', 'februari', '2017', 'and', 'continu', 'to', 'head', 'it', 'charit', 'trust']\n",
      "['3', '4', 'he', 'is', 'the', 'recipi', 'of', 'two', 'civilian', 'award', 'of', 'india', 'the', 'padma', 'vibhushan', '2008', 'the', 'second', 'highest', 'civilian', 'honour', 'and', 'the', 'padma', 'bhushan', '2000', 'the', 'third', 'highest', 'civilian', 'honour']\n",
      "['5', 'born', 'in', '1937', 'he', 'is', 'a', 'heir', 'of', 'the', 'tata', 'famili', 'and', 'son', 'of', 'naval', 'tata', 'who', 'wa', 'later', 'adopt', 'by', 'ratanji', 'tata', 'son', 'of', 'jamsetji', 'tata', 'the', 'founder', 'of', 'tata', 'group']\n",
      "['he', 'is', 'an', 'alumnu', 'of', 'the', 'cornel', 'univers', 'colleg', 'of', 'architectur', 'and', 'harvard', 'busi', 'school', 'through', 'the', 'advanc', 'manag', 'program', 'that', 'he', 'complet', 'in', '1975']\n",
      "['6', 'he', 'join', 'hi', 'compani', 'in', '1961', 'when', 'he', 'use', 'to', 'work', 'on', 'the', 'shop', 'floor', 'of', 'tata', 'steel', 'and', 'wa', 'the', 'appar', 'successor', 'to', 'j', 'r', 'd', 'tata', 'upon', 'the', 'latter', 's', 'retir', 'in', '1991']\n",
      "['he', 'got', 'tata', 'tea', 'to', 'acquir', 'tetley', 'tata', 'motor', 'to', 'acquir', 'jaguar', 'land', 'rover', 'and', 'tata', 'steel', 'to', 'acquir', 'coru', 'in', 'an', 'attempt', 'to', 'turn', 'tata', 'from', 'a', 'larg', 'india', 'centrist', 'group', 'into', 'a', 'global', 'busi']\n",
      "['around', '60', '65', 'of', 'hi', 'profit', 'are', 'donat', 'to', 'chariti', 'make', 'him', 'one', 'of', 'the', 'most', 'signific', 'philanthropist', 'in', 'the', 'world']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    text = re.sub('[^a-zA-Z0-9]',' ',sentences[i])\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words=[stemmer.stem(word) for word in words]\n",
    "    print(words)\n",
    "    corpus.append(' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ratan naval tata ratan born 28 decemb 1937 is an indian industrialist philanthropist and a former chairman of tata son',\n",
       " 'he wa the chairman of tata group from 1990 to 2012 and again as interim chairman from octob 2016 through februari 2017 and continu to head it charit trust',\n",
       " '3 4 he is the recipi of two civilian award of india the padma vibhushan 2008 the second highest civilian honour and the padma bhushan 2000 the third highest civilian honour',\n",
       " '5 born in 1937 he is a heir of the tata famili and son of naval tata who wa later adopt by ratanji tata son of jamsetji tata the founder of tata group',\n",
       " 'he is an alumnu of the cornel univers colleg of architectur and harvard busi school through the advanc manag program that he complet in 1975',\n",
       " '6 he join hi compani in 1961 when he use to work on the shop floor of tata steel and wa the appar successor to j r d tata upon the latter s retir in 1991',\n",
       " 'he got tata tea to acquir tetley tata motor to acquir jaguar land rover and tata steel to acquir coru in an attempt to turn tata from a larg india centrist group into a global busi',\n",
       " 'around 60 65 of hi profit are donat to chariti make him one of the most signific philanthropist in the world']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 4, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 2, 0, 0, 0, 3, 0, 0, 2, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 4, 1, 1, 0, 0, 0, 0, 4, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratan': 89,\n",
       " 'naval': 80,\n",
       " 'tata': 101,\n",
       " 'born': 28,\n",
       " '28': 10,\n",
       " 'decemb': 42,\n",
       " '1937': 0,\n",
       " 'is': 67,\n",
       " 'an': 18,\n",
       " 'indian': 63,\n",
       " 'industrialist': 64,\n",
       " 'philanthropist': 86,\n",
       " 'and': 19,\n",
       " 'former': 47,\n",
       " 'chairman': 32,\n",
       " 'of': 82,\n",
       " 'son': 98,\n",
       " 'he': 54,\n",
       " 'wa': 116,\n",
       " 'the': 105,\n",
       " 'group': 52,\n",
       " 'from': 49,\n",
       " '1990': 3,\n",
       " 'to': 108,\n",
       " '2012': 7,\n",
       " 'again': 16,\n",
       " 'as': 24,\n",
       " 'interim': 65,\n",
       " 'octob': 81,\n",
       " '2016': 8,\n",
       " 'through': 107,\n",
       " 'februari': 45,\n",
       " '2017': 9,\n",
       " 'continu': 39,\n",
       " 'head': 55,\n",
       " 'it': 68,\n",
       " 'charit': 33,\n",
       " 'trust': 109,\n",
       " 'recipi': 91,\n",
       " 'two': 111,\n",
       " 'civilian': 35,\n",
       " 'award': 26,\n",
       " 'india': 62,\n",
       " 'padma': 85,\n",
       " 'vibhushan': 115,\n",
       " '2008': 6,\n",
       " 'second': 95,\n",
       " 'highest': 58,\n",
       " 'honour': 60,\n",
       " 'bhushan': 27,\n",
       " '2000': 5,\n",
       " 'third': 106,\n",
       " 'in': 61,\n",
       " 'heir': 56,\n",
       " 'famili': 44,\n",
       " 'who': 118,\n",
       " 'later': 74,\n",
       " 'adopt': 14,\n",
       " 'by': 30,\n",
       " 'ratanji': 90,\n",
       " 'jamsetji': 70,\n",
       " 'founder': 48,\n",
       " 'alumnu': 17,\n",
       " 'cornel': 40,\n",
       " 'univers': 112,\n",
       " 'colleg': 36,\n",
       " 'architectur': 21,\n",
       " 'harvard': 53,\n",
       " 'busi': 29,\n",
       " 'school': 94,\n",
       " 'advanc': 15,\n",
       " 'manag': 77,\n",
       " 'program': 88,\n",
       " 'that': 104,\n",
       " 'complet': 38,\n",
       " '1975': 2,\n",
       " 'join': 71,\n",
       " 'hi': 57,\n",
       " 'compani': 37,\n",
       " '1961': 1,\n",
       " 'when': 117,\n",
       " 'use': 114,\n",
       " 'work': 119,\n",
       " 'on': 83,\n",
       " 'shop': 96,\n",
       " 'floor': 46,\n",
       " 'steel': 99,\n",
       " 'appar': 20,\n",
       " 'successor': 100,\n",
       " 'upon': 113,\n",
       " 'latter': 75,\n",
       " 'retir': 92,\n",
       " '1991': 4,\n",
       " 'got': 51,\n",
       " 'tea': 102,\n",
       " 'acquir': 13,\n",
       " 'tetley': 103,\n",
       " 'motor': 79,\n",
       " 'jaguar': 69,\n",
       " 'land': 72,\n",
       " 'rover': 93,\n",
       " 'coru': 41,\n",
       " 'attempt': 25,\n",
       " 'turn': 110,\n",
       " 'larg': 73,\n",
       " 'centrist': 31,\n",
       " 'into': 66,\n",
       " 'global': 50,\n",
       " 'around': 23,\n",
       " '60': 11,\n",
       " '65': 12,\n",
       " 'profit': 87,\n",
       " 'are': 22,\n",
       " 'donat': 43,\n",
       " 'chariti': 34,\n",
       " 'make': 76,\n",
       " 'him': 59,\n",
       " 'one': 84,\n",
       " 'most': 78,\n",
       " 'signific': 97,\n",
       " 'world': 120}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-TDF { Term Frequency - Inverse Document Frequency }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21085521, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.25159376, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18195074, 0.11230773,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21085521, 0.        ,\n",
       "        0.        , 0.        , 0.21085521, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25159376, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.25159376, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.25159376, 0.25159376,\n",
       "        0.        , 0.        , 0.1595307 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21085521, 0.        , 0.11230773, 0.        , 0.        ,\n",
       "        0.        , 0.21085521, 0.        , 0.        , 0.50318752,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.21085521, 0.        ,\n",
       "        0.        , 0.28242438, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.20086005, 0.        ,\n",
       "        0.        , 0.        , 0.20086005, 0.20086005, 0.20086005,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20086005, 0.        , 0.        , 0.1793219 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.20086005,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.3366728 , 0.20086005, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.20086005,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20086005, 0.        , 0.        , 0.        , 0.3366728 ,\n",
       "        0.        , 0.        , 0.1452605 , 0.        , 0.10037193,\n",
       "        0.20086005, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20086005, 0.        , 0.        , 0.20086005, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20086005, 0.08966095, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.11273685, 0.        , 0.        , 0.        ,\n",
       "        0.10037193, 0.        , 0.1683364 , 0.25472289, 0.20086005,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1452605 , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16096985, 0.16096985, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.07185455,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16096985, 0.16096985, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.48290954, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08043836,\n",
       "        0.        , 0.        , 0.        , 0.32193969, 0.        ,\n",
       "        0.32193969, 0.        , 0.13490529, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.10206784, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14370911, 0.        , 0.        ,\n",
       "        0.32193969, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16096985, 0.        , 0.        , 0.        ,\n",
       "        0.16096985, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40219182, 0.16096985, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16096985, 0.        , 0.        , 0.        ,\n",
       "        0.16096985, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.15784355, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18833992,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08407215,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15784355, 0.        ,\n",
       "        0.18833992, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18833992,\n",
       "        0.        , 0.        , 0.        , 0.18833992, 0.        ,\n",
       "        0.        , 0.        , 0.13620603, 0.        , 0.09411548,\n",
       "        0.        , 0.18833992, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.10570967, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.11942267, 0.        , 0.        ,\n",
       "        0.18833992, 0.        , 0.        , 0.        , 0.18833992,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15784355, 0.        , 0.33628859, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.18833992, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3156871 , 0.        ,\n",
       "        0.        , 0.52854833, 0.        , 0.        , 0.        ,\n",
       "        0.18823097, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13620603, 0.        , 0.18833992, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.23162783, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23162783, 0.        , 0.23162783, 0.16751153, 0.10339523,\n",
       "        0.        , 0.23162783, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1941222 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.23162783, 0.        , 0.23162783, 0.        ,\n",
       "        0.23162783, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23162783, 0.23149384,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.1300059 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.14687069, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23162783, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20679046, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.23162783, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23162783,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.23162783,\n",
       "        0.23149384, 0.        , 0.1941222 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.23162783, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.20120705, 0.        , 0.        , 0.20120705,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.08981584,\n",
       "        0.20120705, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20120705, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20120705, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.20109066,\n",
       "        0.        , 0.        , 0.16862721, 0.        , 0.        ,\n",
       "        0.        , 0.22586322, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.20120705, 0.        , 0.        , 0.        ,\n",
       "        0.20120705, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08981584, 0.20120705, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20120705, 0.        , 0.        ,\n",
       "        0.        , 0.20120705, 0.        , 0.        , 0.16862721,\n",
       "        0.20120705, 0.22586322, 0.        , 0.        , 0.        ,\n",
       "        0.30163598, 0.        , 0.        , 0.25516294, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.20120705, 0.20120705,\n",
       "        0.        , 0.14551145, 0.20120705, 0.        , 0.20120705,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.47981373, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11566591, 0.07139391,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.15993791, 0.        , 0.        , 0.        , 0.13404045,\n",
       "        0.        , 0.15993791, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15993791, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.13404045,\n",
       "        0.15993791, 0.15993791, 0.11566591, 0.        , 0.0799227 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.08976845, 0.13404045, 0.        , 0.        ,\n",
       "        0.        , 0.15993791, 0.        , 0.        , 0.15993791,\n",
       "        0.        , 0.        , 0.15993791, 0.15993791, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.15993791,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.15993791, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.13404045,\n",
       "        0.        , 0.35907381, 0.15993791, 0.15993791, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.40565405, 0.        ,\n",
       "        0.15993791, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24312474, 0.24312474, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24312474, 0.24312474, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24312474,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.24312474, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.20375751, 0.        , 0.24312474,\n",
       "        0.        , 0.13645878, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.24312474, 0.        , 0.24312474, 0.        ,\n",
       "        0.        , 0.        , 0.21705456, 0.        , 0.24312474,\n",
       "        0.        , 0.20375751, 0.24312474, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.24312474, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2429841 , 0.        , 0.        , 0.15416066, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24312474]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ratan': 89,\n",
       " 'naval': 80,\n",
       " 'tata': 101,\n",
       " 'born': 28,\n",
       " '28': 10,\n",
       " 'decemb': 42,\n",
       " '1937': 0,\n",
       " 'is': 67,\n",
       " 'an': 18,\n",
       " 'indian': 63,\n",
       " 'industrialist': 64,\n",
       " 'philanthropist': 86,\n",
       " 'and': 19,\n",
       " 'former': 47,\n",
       " 'chairman': 32,\n",
       " 'of': 82,\n",
       " 'son': 98,\n",
       " 'he': 54,\n",
       " 'wa': 116,\n",
       " 'the': 105,\n",
       " 'group': 52,\n",
       " 'from': 49,\n",
       " '1990': 3,\n",
       " 'to': 108,\n",
       " '2012': 7,\n",
       " 'again': 16,\n",
       " 'as': 24,\n",
       " 'interim': 65,\n",
       " 'octob': 81,\n",
       " '2016': 8,\n",
       " 'through': 107,\n",
       " 'februari': 45,\n",
       " '2017': 9,\n",
       " 'continu': 39,\n",
       " 'head': 55,\n",
       " 'it': 68,\n",
       " 'charit': 33,\n",
       " 'trust': 109,\n",
       " 'recipi': 91,\n",
       " 'two': 111,\n",
       " 'civilian': 35,\n",
       " 'award': 26,\n",
       " 'india': 62,\n",
       " 'padma': 85,\n",
       " 'vibhushan': 115,\n",
       " '2008': 6,\n",
       " 'second': 95,\n",
       " 'highest': 58,\n",
       " 'honour': 60,\n",
       " 'bhushan': 27,\n",
       " '2000': 5,\n",
       " 'third': 106,\n",
       " 'in': 61,\n",
       " 'heir': 56,\n",
       " 'famili': 44,\n",
       " 'who': 118,\n",
       " 'later': 74,\n",
       " 'adopt': 14,\n",
       " 'by': 30,\n",
       " 'ratanji': 90,\n",
       " 'jamsetji': 70,\n",
       " 'founder': 48,\n",
       " 'alumnu': 17,\n",
       " 'cornel': 40,\n",
       " 'univers': 112,\n",
       " 'colleg': 36,\n",
       " 'architectur': 21,\n",
       " 'harvard': 53,\n",
       " 'busi': 29,\n",
       " 'school': 94,\n",
       " 'advanc': 15,\n",
       " 'manag': 77,\n",
       " 'program': 88,\n",
       " 'that': 104,\n",
       " 'complet': 38,\n",
       " '1975': 2,\n",
       " 'join': 71,\n",
       " 'hi': 57,\n",
       " 'compani': 37,\n",
       " '1961': 1,\n",
       " 'when': 117,\n",
       " 'use': 114,\n",
       " 'work': 119,\n",
       " 'on': 83,\n",
       " 'shop': 96,\n",
       " 'floor': 46,\n",
       " 'steel': 99,\n",
       " 'appar': 20,\n",
       " 'successor': 100,\n",
       " 'upon': 113,\n",
       " 'latter': 75,\n",
       " 'retir': 92,\n",
       " '1991': 4,\n",
       " 'got': 51,\n",
       " 'tea': 102,\n",
       " 'acquir': 13,\n",
       " 'tetley': 103,\n",
       " 'motor': 79,\n",
       " 'jaguar': 69,\n",
       " 'land': 72,\n",
       " 'rover': 93,\n",
       " 'coru': 41,\n",
       " 'attempt': 25,\n",
       " 'turn': 110,\n",
       " 'larg': 73,\n",
       " 'centrist': 31,\n",
       " 'into': 66,\n",
       " 'global': 50,\n",
       " 'around': 23,\n",
       " '60': 11,\n",
       " '65': 12,\n",
       " 'profit': 87,\n",
       " 'are': 22,\n",
       " 'donat': 43,\n",
       " 'chariti': 34,\n",
       " 'make': 76,\n",
       " 'him': 59,\n",
       " 'one': 84,\n",
       " 'most': 78,\n",
       " 'signific': 97,\n",
       " 'world': 120}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['I want to have food']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OOV Issue for above data to overcome this we use DL technique Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "831c8d92a2d4b33b6bdbd930f80d233dd70f2371e2d79e4c68745108a666f2d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
